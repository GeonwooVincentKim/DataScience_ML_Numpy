1. Nabla (Del Operator)
- 1. 물리학에서 연산자는 함수를 함수에 대응시키는 함수를 말함
- 2. Del Operator (Nabla) -> 어떤 함수가 주어졌을 때, 그 함수의 도함수를 함숫값으로 가지는 함수
- 3. ∇ -> Nabla 기호
- 4. 기본적인 미분의 식 -> dx/d *(f) = f′
- 5. Del Operator (Nabla) -> ∇ = ∂/∂x * x^ + ∂/∂y * y^ + ∂/∂z * z^

	
2. 소프트맥스 연산
- 1. 입력받은 값을 출력으로 0 ~ 1 사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수
- 2. SoftMax 는 Binary Classification 이 아닌 Multiclass Clasification 를 지원
- 3. SoftMax Classification 의 Cost Function
  = 1. Input Parameter 에 대한 우도를 평가, 최대화하는 방법으로 cost function 을 만들어 냄
  = 2. 일반적으로 SoftMax Classifier 를 만들어 내는 경우, 정답 Class 를 one-hot encoding 의 방법으로 학습


3. 시그모이드 함수
- 1. 입력에 대해 0 과 1사이의 값 출력, 절대값이 크면 0이나 1로 수렴함
- 2. 큰 값이어도 1을 넘는 값을 가질 수 없고, 아무리 작은 값도 0에 가까운 값을 가짐
- 3. SigMoid 를 활성화 함수로 사용 시, 1보다 작은 출력 값이 매 층마다 곱해지면서 점점 값이 작아지게 됨


4. Tanh (하이퍼볼릭 탄젠트)
- 1. 시그모이의 함수의 범위를 -1 에서 1로 확장한 개념
- 2. 마치 복선으로 놓여진 철로에서 한쪽에서 다른 한쪽 선로로 넘어갈 수 있도록 해주는 선로분기기와 같음
- 3. 입력의 절대값이 클 경우, -1 이나 1로 수렴하므로, 기울기 소실 문제는 여전히 존재함


5. ReLU
- 1. 입력이 음수면 0, 양수면 입력 값 그대로 출력
- 2. 모든 1차 함수 Graph 경사하강법의 평균을 구해 Vector 형태의 선으로 나타낸 것처럼 0부터 입력 값까지 규칙적으로 출력
- 3. 기울기 손실문제 해결, 신경망의 깊이 제약 문제를 해결하는데 큰 역할을 함
